# qwen-local
qwen 2.5 14b LLM running locally - no cloud, no API keys 
Hardware Ryzen 7 5800x3D , Nvidia 3080 , 32GB DDR4 Ram 

Running qwen 2.5 14B entirely offline via llama.ccp on Ubuntu-No Gui just terminal 

using command curl -fsSL https://ollama.com/install.sh | sh -  in the terminal * this will install ollama*

then command ollama run qwen2.5:14b *or whatever model you wish to use*

<img width="647" height="431" alt="Screenshot from 2026-01-07 13-59-46" src="https://github.com/user-attachments/assets/00c099ef-cc3b-44b8-b2ac-cfc81ea8e4f2" />

*some nice commands*

ollama run qwen2.5:14b - opens ai bot ollama

ollama list - shows models on pc 

ollama rm + name - removes model 
